---
layout: post
title: 'Machine Malware Predictoin'
---
**Introduction**

Computers, cell phones, and tablets are affected by malware daily. Nearly one-third of the devices in the world are infected with some form of malware (Mello, 2014). Types of malware include ransomware, spyware, and adware. Malware can sneakily infect a system when an user clicks on a faulty advertisement or downloads a unknown program. With all that being said, it is important to make sure computer users are taking the necessary precautions to prevent their devices from becoming infected by malware.The goal of this project is to predict likeliness of a Windows machine to be hit by malware soon.
<br><br>
**Data**

The data we used for this project is from [Microsoft Malware Prediction - a Kaggle competition](https://www.kaggle.com/c/microsoft-malware-prediction). According to Kaggle, the data is gathered from user Windows Defender threat reports. There are 502,583 observations and 83 variables. Because the data set is large, we went through a series of steps to clean the data. 
<br><br>

**Modeling**
***logistic Regression***
```python
#logistic regression
#https://stackabuse.com/classification-in-python-with-scikit-learn-and-pandas/

#model training and prediction
LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr').fit(X_train, y_train) 
predictions = LR.predict(X_test) 

print(confusion_matrix(y_test,predictions))  
print(classification_report(y_test,predictions))

#calculate the accuracy of the model
y_scores = LR.predict_proba(X_test)
fpr, tpr, threshold = roc_curve(y_test, y_scores[:, 1])
roc_auc = auc(fpr, tpr)

#plot roc curve
plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.title('ROC Curve of LR')
plt.show()
```
![](https://raw.githubusercontent.com/haoyingy/Home/gh-pages/assets/img/projects/proj-5/lg.png)
***Random Forest***
```python
# Random Forests 
from sklearn.ensemble import RandomForestClassifier

#model training and prediction
RF = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=0) 
RF.fit(X_train,y_train)
predictions = RF.predict(X_test) 


print(confusion_matrix(y_test,predictions))  
print(classification_report(y_test,predictions))

#calculate the accuracy of the model
y_scores = RF.predict_proba(X_test)
fpr, tpr, threshold = roc_curve(y_test, y_scores[:, 1])
roc_auc = auc(fpr, tpr)

#plot roc curve
plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.title('ROC Curve of RF')
plt.show()
```
![](https://raw.githubusercontent.com/haoyingy/Home/gh-pages/assets/img/projects/proj-5/rf.png)
***Neural Network***
```python
import sklearn as sk  
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler  
from sklearn.metrics import classification_report, confusion_matrix  

#model training and prediction
NN = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)  
NN.fit(X_train, y_train.values.ravel())   
predictions = NN.predict(X_test) 

print(confusion_matrix(y_test,predictions))  
print(classification_report(y_test,predictions))

#calculate the accuracy of the model
y_scores = NN.predict_proba(X_test)
fpr, tpr, threshold = roc_curve(y_test, y_scores[:, 1])
roc_auc = auc(fpr, tpr)

#plot roc curve
plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.title('ROC Curve of NN')
plt.show()
```
![](https://raw.githubusercontent.com/haoyingy/Home/gh-pages/assets/img/projects/proj-5/nn.png)

**Conclusion**

I produced three different types of models that explored the dataset in explicitly different ways. I first performed the most generic model - logistic regression. The overall area under the curve for this model came out to be 68%, slightly better than half. The random forests model bases its model off of multiple decision trees and produced an AUC value of 66%. However, both the logistic regression and random forests model did not perform as well as the neural network model. The neural network model proved to have AUC value as 69%. Thus, we can conclude that out of all the models that we were able to create the neural network model could be used to help detect malicious malware given that information relating to the attributes used in the model can be provided.

For more details of this project, please find [here](https://github.com/haoyingyang/MicrosoftMalware_project)

